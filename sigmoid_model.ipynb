{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "om namo narayana\n"
     ]
    }
   ],
   "source": [
    "print('om namo narayana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def prediction(x, W):\\n    #here x is a numpy array representing a single input\\n    #this function must return a single float value\\n    activations =[]\\n    #activations is a 1D array\\n    activations.append(x)\\n    for layer in range(len(W)):\\n        activations.append(np.dot(np.array(activations[layer]).reshape(1, len(activations[layer])), W[layer]))\\n    return activations[len(activations) - 1]\\n    '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def prediction(x, W):\n",
    "    #here x is a numpy array representing a single input\n",
    "    #this function must return a single float value\n",
    "    activations =[]\n",
    "    #activations is a 1D array\n",
    "    activations.append(x)\n",
    "    for layer in range(len(W)):\n",
    "        activations.append(np.dot(np.array(activations[layer]).reshape(1, len(activations[layer])), W[layer]))\n",
    "    return activations[len(activations) - 1]\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#input_data is a nupmy array\\ndef SGD(input_data, output_data, dict ={}):\\n    log = {'epochs': 10, 'batch_size': len(input_data)/10, 'maximum_error':10e10 , 'dim_layer': [2, 3, 2], alpha = '0.01'}\\n    for key in log.keys():\\n        if(dict[key] != None):\\n            log[key] = dict[key]\\n    batch_size = log.get('batch_size')\\n    if(batch_size > input_data.shape[0]):\\n        print('invalid batch_size')\\n    dim_layer  = log.get('dim_layer')\\n    max_layer = max(dim_layer)\\n    #check this reshape \\n    my_filter = []\\n    for layer in dim_layers:\\n        my_filter.append(list(np.ones(layer)) + np.zeros((max_layer - layer)))\\n    #check the dimension of filter\\n    my_filter = np.array(my_filter)\\n    input_data = np.array(list(input_data) + list(input_data[:len(input_data)%batch_size])).reshape(len(input_data)/batch_size, batch_size, len(input_data[0]))\\n    for epoch in range(log.get('epochs')):\\n        W = np.random.randint(1, 10, [len(dim_layers) - 1, max_layer, max_layer])\\n        #bias = np.random.randint(1, 10, [len(dim_layers) - 1, max_layer])\\n        for batch in range(len(input_data)/batch_size):\\n            X = batch_size(batch*len(input_data[0]), (batch + 1)*len(input_data[0]))\\n            predictions = [prediction(X[i]) for i in range(batch_size)]\\n                activations = []\\n                activations.append(X[data])\\n                for layer in range(len(dim_layer) - 2):\\n                    #check the dimensions properly\\n                    activations.append(np.dot(activation[layer] ,W[layer][:dim_layer[layer] + 1])) \\n            #lengh of activations and weights should be len(dim_layer) - 1\\n            #W[1].shape = (3, 2)\\n            #W[0].shape = (2, 3)\\n            #dif.shape = (1, 2)\\n            #x.shape = (1, 2)\\n            #np.dot(dif, W[1].T).shape  = (1, 3)\\n            #np.dot(W[1])\\n            #single output is a 1D array\\n            #activations[0] is a 1D array\\n            #dif is a 1_D array\\n            \\n            A = W[:]\\n            dif = np.array(activations[len(activations) - 1] - y_train).mean(axis = 0)\\n            W[1] -= alpha*np.dot(activations[1].reshape(len(activations[1]), 1) , dif.reshape(1, len(dif)))\\n            #bias[1] -= alpha * dif\\n            matrix =  np.dot(dif.reshape(1, len(dif)), A[1].T)\\n            W[0] -=  alpha * np.dot(activations[0].reshape(len(activations[0]), 1), matrix.reshape(1, len(matrix)))\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#input_data is a nupmy array\n",
    "def SGD(input_data, output_data, dict ={}):\n",
    "    log = {'epochs': 10, 'batch_size': len(input_data)/10, 'maximum_error':10e10 , 'dim_layer': [2, 3, 2], alpha = '0.01'}\n",
    "    for key in log.keys():\n",
    "        if(dict[key] != None):\n",
    "            log[key] = dict[key]\n",
    "    batch_size = log.get('batch_size')\n",
    "    if(batch_size > input_data.shape[0]):\n",
    "        print('invalid batch_size')\n",
    "    dim_layer  = log.get('dim_layer')\n",
    "    max_layer = max(dim_layer)\n",
    "    #check this reshape \n",
    "    my_filter = []\n",
    "    for layer in dim_layers:\n",
    "        my_filter.append(list(np.ones(layer)) + np.zeros((max_layer - layer)))\n",
    "    #check the dimension of filter\n",
    "    my_filter = np.array(my_filter)\n",
    "    input_data = np.array(list(input_data) + list(input_data[:len(input_data)%batch_size])).reshape(len(input_data)/batch_size, batch_size, len(input_data[0]))\n",
    "    for epoch in range(log.get('epochs')):\n",
    "        W = np.random.randint(1, 10, [len(dim_layers) - 1, max_layer, max_layer])\n",
    "        #bias = np.random.randint(1, 10, [len(dim_layers) - 1, max_layer])\n",
    "        for batch in range(len(input_data)/batch_size):\n",
    "            X = batch_size(batch*len(input_data[0]), (batch + 1)*len(input_data[0]))\n",
    "            predictions = [prediction(X[i]) for i in range(batch_size)]\n",
    "                activations = []\n",
    "                activations.append(X[data])\n",
    "                for layer in range(len(dim_layer) - 2):\n",
    "                    #check the dimensions properly\n",
    "                    activations.append(np.dot(activation[layer] ,W[layer][:dim_layer[layer] + 1])) \n",
    "            #lengh of activations and weights should be len(dim_layer) - 1\n",
    "            #W[1].shape = (3, 2)\n",
    "            #W[0].shape = (2, 3)\n",
    "            #dif.shape = (1, 2)\n",
    "            #x.shape = (1, 2)\n",
    "            #np.dot(dif, W[1].T).shape  = (1, 3)\n",
    "            #np.dot(W[1])\n",
    "            #single output is a 1D array\n",
    "            #activations[0] is a 1D array\n",
    "            #dif is a 1_D array\n",
    "            \n",
    "            A = W[:]\n",
    "            dif = np.array(activations[len(activations) - 1] - y_train).mean(axis = 0)\n",
    "            W[1] -= alpha*np.dot(activations[1].reshape(len(activations[1]), 1) , dif.reshape(1, len(dif)))\n",
    "            #bias[1] -= alpha * dif\n",
    "            matrix =  np.dot(dif.reshape(1, len(dif)), A[1].T)\n",
    "            W[0] -=  alpha * np.dot(activations[0].reshape(len(activations[0]), 1), matrix.reshape(1, len(matrix)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def trial(a = {'a':1, 'b':2}):\\n    b = {'a':1, 'b':2}\\n    print(a.get('a'), a.get('b'))\\n    for key in b.keys():\\n        if a.get(key) != None:\\n            b[key] = a[key]\\n        print(b.get(key))\\ntrial({'a':3})\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def trial(a = {'a':1, 'b':2}):\n",
    "    b = {'a':1, 'b':2}\n",
    "    print(a.get('a'), a.get('b'))\n",
    "    for key in b.keys():\n",
    "        if a.get(key) != None:\n",
    "            b[key] = a[key]\n",
    "        print(b.get(key))\n",
    "trial({'a':3})'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A = np.random.randint(1, 3, [3, 2])\\nB = np.random.randint(1, 3 ,[2, 3])\\nO = np.random.randint(1, 3, [1, 2])\\nI = np.random.randint(1, 3, [1, 3])\\nprint(A.tolist())\\nprint(B.tolist())\\nprint(np.dot(A, B).shape)\\nprint(np.dot(B, A).shape)\\n#print(np.dot(O, A))\\nprint(np.dot(O, A.T))\\nprint(np.dot(A.T, O))#invalid'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''A = np.random.randint(1, 3, [3, 2])\n",
    "B = np.random.randint(1, 3 ,[2, 3])\n",
    "O = np.random.randint(1, 3, [1, 2])\n",
    "I = np.random.randint(1, 3, [1, 3])\n",
    "print(A.tolist())\n",
    "print(B.tolist())\n",
    "print(np.dot(A, B).shape)\n",
    "print(np.dot(B, A).shape)\n",
    "#print(np.dot(O, A))\n",
    "print(np.dot(O, A.T))\n",
    "print(np.dot(A.T, O))#invalid'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'activation = np.random.randint(1, 3, [3,])\\nA = np.random.randint(1, 4, [2, 3])\\nprint(activation.tolist(), A.tolist())\\nprint(np.dot(A, activation).tolist())'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''activation = np.random.randint(1, 3, [3,])\n",
    "A = np.random.randint(1, 4, [2, 3])\n",
    "print(activation.tolist(), A.tolist())\n",
    "print(np.dot(A, activation).tolist())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'activation = np.random.randint(1, 3, [2,])\\nA = np.random.randint(1, 4, [2, 3])\\nprint(activation.tolist(), A.tolist())\\nprint(np.dot(A.T, activation).tolist())\\nprint(np.dot(A, activation.T).tolist())'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''activation = np.random.randint(1, 3, [2,])\n",
    "A = np.random.randint(1, 4, [2, 3])\n",
    "print(activation.tolist(), A.tolist())\n",
    "print(np.dot(A.T, activation).tolist())\n",
    "print(np.dot(A, activation.T).tolist())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'activation = np.random.randint(1, 3, [1, 3])\\nA = np.random.randint(1, 4, [2, 3])\\nprint(activation.tolist(), A.tolist())\\nprint(np.dot(A, activation).tolist())'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''activation = np.random.randint(1, 3, [1, 3])\n",
    "A = np.random.randint(1, 4, [2, 3])\n",
    "print(activation.tolist(), A.tolist())\n",
    "print(np.dot(A, activation).tolist())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A = np.arange(1, 5).reshape(2 , 2)\\nprint(A)\\nB = np.arange(5, 9).reshape(2, 2)\\nprint(B)\\nprint(np.dot(A, B.T).tolist())\\nprint(np.dot(B.T, A).tolist())\\nprint(np.dot(A.T, B).tolist())\\nprint(np.dot(B, A.T).tolist())\\nprint(np.dot(A, B).tolist())\\nprint(np.dot(B, A).tolist())'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''A = np.arange(1, 5).reshape(2 , 2)\n",
    "print(A)\n",
    "B = np.arange(5, 9).reshape(2, 2)\n",
    "print(B)\n",
    "print(np.dot(A, B.T).tolist())\n",
    "print(np.dot(B.T, A).tolist())\n",
    "print(np.dot(A.T, B).tolist())\n",
    "print(np.dot(B, A.T).tolist())\n",
    "print(np.dot(A, B).tolist())\n",
    "print(np.dot(B, A).tolist())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(z):\n",
    "    return np.exp(-z)/(1 + np.exp(-z))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_W(dim_layer):\n",
    "    W = []\n",
    "    for layer in range(len(dim_layer) - 1):\n",
    "        W.append(np.random.randint(1, 4, [dim_layer[layer], dim_layer[layer+1]]) *1.0)\n",
    "    return W\n",
    "    #W is a 3D list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_bias(dim_layer):\n",
    "    bias = []\n",
    "\n",
    "    for layer in range(len(dim_layer) - 1):\n",
    "        bias.append(np.random.randint(1, 3, [dim_layer[layer+1]]) * 1.0)\n",
    "    return bias\n",
    "    #bias is a 2D list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(X, W, bias):\n",
    "    X = np.array(X)\n",
    "    activations = []\n",
    "    input_values = []\n",
    "    input_values.append(X)\n",
    "    activations.append(sigmoid(X))\n",
    "    for layer in range(len(W)):\n",
    "        input_values.append(np.dot(W[layer].T, (activations[layer]).reshape(activations[layer].shape[0], 1)).T[0])\n",
    "        activations.append(np.dot(W[layer].T, sigmoid(activations[layer]).reshape(activations[layer].shape[0], 1)).T[0] + bias[layer])\n",
    "    return activations, input_values\n",
    "    #activations is a 2D list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(X, W, bias):\n",
    "    activations = sigmoid(X)\n",
    "    for layer in range(len(W)):\n",
    "        activations = np.dot(W[layer].T, sigmoid(activations).reshape(activations.shape[0], 1)).T[0] + bias[layer]\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(X, Y, W, b, activations, input_values, dim_layer, alpha):\n",
    "    A = W[:]\n",
    "    l = len(dim_layer) - 1\n",
    "    matrix = np.product([list(np.array(activations[l] - Y)), list(np.array(sigmoid_derivative(input_values[l])))], axis = 0)\n",
    "    for i in range(len(dim_layer) - 1):\n",
    "        W[l - 1 - i] = A[l - 1 - i] - alpha *  np.dot(activations[l - i - 1].reshape(activations[l - 1 - i].shape[0], 1) , matrix.reshape(1, len(matrix))) \n",
    "        b[l - 1 - i] -= alpha * matrix\n",
    "        matrix = np.product([list(np.dot(matrix.reshape(1, matrix.shape[0]), A[l - 1 - i].T)[0]), list(np.array(sigmoid_derivative(input_values[l - 1 - i])))], axis = 0)\n",
    "        #while inner product matrix is converted to shape (1, x)\n",
    "    return(W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(X, Y, W ,bias):\n",
    "    #X is a single input numpy array and Y is the single output numpy array\n",
    "    predictions = get_prediction(X, W, bias)\n",
    "    error = sum((predictions - Y)**2)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_test_data, output_test_data, W, bias):\n",
    "    predictions = np.array([get_prediction(input_test_data[i], W, bias) for i in range(input_test_data.shape[0])])\n",
    "    error = np.sum((predictions/pow(input_test_data.shape[0], 0.5) - output_test_data/pow(input_test_data.shape[0], 0.5))**2)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data is a nupmy array\n",
    "def mini_SGD(input_data, output_data, input_test_data, output_test_data, dict_ ={}):\n",
    "    \n",
    "    \n",
    "    log = {'epochs': 10, 'maximum_error':10e10 , 'dim_layer': [2, 3, 2], 'alpha' : 0.01}\n",
    "    for key in log.keys():\n",
    "        if(dict_[key] != None):\n",
    "            log[key] = dict_[key]\n",
    "    dim_layer  = log.get('dim_layer')\n",
    "    alpha = log.get('alpha')\n",
    "    error_list = []\n",
    "    weight_list = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(log.get('epochs')):\n",
    "        print('\\n\\nepoch_number:{}'.format(epoch+1))\n",
    "        W = get_random_W(dim_layer)\n",
    "        bias = get_random_bias(dim_layer)\n",
    "\n",
    "        for i in range(input_data.shape[0]):\n",
    "            activations, input_values = get_activations(input_data[i], W, bias)\n",
    "            W, bias = back_prop(input_data[i], output_data[i], W, bias, activations, input_values, dim_layer, log.get('alpha'))\n",
    "            error = get_error(input_data[i], output_data[i], W, bias)\n",
    "            #print('{} :error: {}'.format(i+1, error))\n",
    "        batch_error = evaluate(input_test_data, output_test_data, W, bias)\n",
    "        error_list.append(batch_error)\n",
    "        weight_list.append((W, bias))\n",
    "        print('batch_error:{}'.format(batch_error))\n",
    "        #print('error:{}'.format(error))\n",
    "    return weight_list[error_list.index(min(error_list))], min(error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.random.randint(1, 100, [10000, 2])\n",
    "output_data = input_data * 3.0\n",
    "input_test_data = np.random.randint(1, 100, [100, 2])\n",
    "output_test_data = input_test_data * 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "epoch_number:1\n",
      "batch_error:55827.54731780512\n",
      "\n",
      "\n",
      "epoch_number:2\n",
      "batch_error:55679.19524765906\n",
      "\n",
      "\n",
      "epoch_number:3\n",
      "batch_error:55675.992570992035\n",
      "\n",
      "\n",
      "epoch_number:4\n",
      "batch_error:54239.66497361036\n",
      "\n",
      "\n",
      "epoch_number:5\n",
      "batch_error:57076.89145634726\n",
      "\n",
      "\n",
      "epoch_number:6\n",
      "batch_error:55365.46396640734\n",
      "\n",
      "\n",
      "epoch_number:7\n",
      "batch_error:55221.91476381538\n",
      "\n",
      "\n",
      "epoch_number:8\n",
      "batch_error:55955.735982695944\n",
      "\n",
      "\n",
      "epoch_number:9\n",
      "batch_error:55708.734108034594\n",
      "\n",
      "\n",
      "epoch_number:10\n",
      "batch_error:55976.77465179565\n",
      "\n",
      "\n",
      "epoch_number:11\n",
      "batch_error:55160.22110335485\n",
      "\n",
      "\n",
      "epoch_number:12\n",
      "batch_error:54827.50105001129\n",
      "\n",
      "\n",
      "epoch_number:13\n",
      "batch_error:55697.05193938805\n",
      "\n",
      "\n",
      "epoch_number:14\n",
      "batch_error:55401.93576737867\n",
      "\n",
      "\n",
      "epoch_number:15\n",
      "batch_error:54252.88622424412\n",
      "\n",
      "\n",
      "epoch_number:16\n",
      "batch_error:55462.178329963914\n",
      "\n",
      "\n",
      "epoch_number:17\n",
      "batch_error:55671.08095197701\n",
      "\n",
      "\n",
      "epoch_number:18\n",
      "batch_error:55109.96788197823\n",
      "\n",
      "\n",
      "epoch_number:19\n",
      "batch_error:55317.35187477709\n",
      "\n",
      "\n",
      "epoch_number:20\n",
      "batch_error:57318.98636621245\n",
      "\n",
      "\n",
      "epoch_number:21\n",
      "batch_error:56569.65745930864\n",
      "\n",
      "\n",
      "epoch_number:22\n",
      "batch_error:55073.143105521754\n",
      "\n",
      "\n",
      "epoch_number:23\n",
      "batch_error:56747.531891692364\n",
      "\n",
      "\n",
      "epoch_number:24\n",
      "batch_error:55848.399851766764\n",
      "\n",
      "\n",
      "epoch_number:25\n",
      "batch_error:55384.796847300415\n",
      "\n",
      "\n",
      "epoch_number:26\n",
      "batch_error:55037.65049624686\n",
      "\n",
      "\n",
      "epoch_number:27\n",
      "batch_error:55508.48709934854\n",
      "\n",
      "\n",
      "epoch_number:28\n",
      "batch_error:55897.885185448344\n",
      "\n",
      "\n",
      "epoch_number:29\n",
      "batch_error:54512.84872437453\n",
      "\n",
      "\n",
      "epoch_number:30\n",
      "batch_error:56501.6745739427\n",
      "\n",
      "\n",
      "epoch_number:31\n",
      "batch_error:54783.42543780942\n",
      "\n",
      "\n",
      "epoch_number:32\n",
      "batch_error:55392.10720593655\n",
      "\n",
      "\n",
      "epoch_number:33\n",
      "batch_error:55358.9130702451\n",
      "\n",
      "\n",
      "epoch_number:34\n",
      "batch_error:55579.11442295137\n",
      "\n",
      "\n",
      "epoch_number:35\n",
      "batch_error:56210.989460142315\n",
      "\n",
      "\n",
      "epoch_number:36\n",
      "batch_error:54806.4015936989\n",
      "\n",
      "\n",
      "epoch_number:37\n",
      "batch_error:55690.01789450082\n",
      "\n",
      "\n",
      "epoch_number:38\n",
      "batch_error:55926.30851124025\n",
      "\n",
      "\n",
      "epoch_number:39\n",
      "batch_error:55891.111415217274\n",
      "\n",
      "\n",
      "epoch_number:40\n",
      "batch_error:55765.67820249225\n",
      "\n",
      "\n",
      "epoch_number:41\n",
      "batch_error:54047.974098769395\n",
      "\n",
      "\n",
      "epoch_number:42\n",
      "batch_error:56259.824617852195\n",
      "\n",
      "\n",
      "epoch_number:43\n",
      "batch_error:55410.79888913399\n",
      "\n",
      "\n",
      "epoch_number:44\n",
      "batch_error:55708.12925174995\n",
      "\n",
      "\n",
      "epoch_number:45\n",
      "batch_error:56024.317127048285\n",
      "\n",
      "\n",
      "epoch_number:46\n"
     ]
    }
   ],
   "source": [
    "A, error = mini_SGD(input_data, output_data, input_test_data, output_test_data, {'epochs': 100, 'maximum_error':10e10 , 'dim_layer': [2, 3, 2], 'alpha' : 0.0000001})\n",
    "print(A)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(alpha, epochs):\n",
    "    input_data = np.random.randint(1, 100, [10000, 1])\n",
    "    output_data = input_data * 2\n",
    "    print(output_data.shape)\n",
    "    print\n",
    "    input_test_data = np.random.randint(1, 100, [100, 1])\n",
    "    output_test_data = input_test_data * 2\n",
    "    print('*********WITH 1 HIDDEN LAYER***********\\n\\n\\n')\n",
    "    A, error = mini_SGD(input_data, output_data, input_test_data, output_test_data, {'epochs':epochs, 'maximum_error':10e10, 'dim_layer': [1, 1, 1], 'alpha' : alpha })\n",
    "    print('min error',error)\n",
    "    print('\\n\\n\\n*********WITH 1 HIDDEN LAYER***********')\n",
    "    print('*********2 PERCEPTRON IN HIDDEN LAYER********\\n\\n\\n')\n",
    "    A, error = mini_SGD(input_data, output_data, input_test_data, output_test_data, {'epochs':epochs, 'maximum_error':10e10, 'dim_layer': [1, 2, 1], 'alpha' : alpha })\n",
    "    print('min error', error)\n",
    "    print('\\n\\n\\n*********WITH 2 HIDDEN LAYERS**********\\n\\n\\n')\n",
    "    A, error = mini_SGD(input_data, output_data, input_test_data, output_test_data, {'epochs':epochs, 'maximum_error':10e10, 'dim_layer': [1, 1, 1, 1], 'alpha' : alpha })\n",
    "    print('min error', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(alpha, epochs):\n",
    "    input_data = np.random.randint(1, 100, [10000, 2])\n",
    "    output_data = (input_data.T[0] * 3 + input_data.T[1] * 4).reshape(input_data.shape[0], 1)\n",
    "    input_test_data = np.random.randint(1, 100, [100, 2])\n",
    "    output_test_data = (input_test_data.T[0] * 3 + input_test_data.T[1] * 4).reshape(input_test_data.shape[0], 1)\n",
    "    print('*********WITH 1 HIDDEN LAYER***********\\n\\n\\n')\n",
    "    A, error = mini_SGD(input_data, output_data, input_test_data, output_test_data, {'epochs':epochs, 'maximum_error':10e10, 'dim_layer': [2, 1, 1], 'alpha' : alpha })\n",
    "    print(error)\n",
    "    print('\\n\\n\\n*********WITH 1 HIDDEN LAYER***********')\n",
    "    print('*********2 PERCEPTRON IN HIDDEN LAYER********\\n\\n\\n')\n",
    "    A, error = mini_SGD(input_data, output_data, input_test_data, output_test_data, {'epochs':epochs, 'maximum_error':10e10, 'dim_layer': [2, 2, 1], 'alpha' : alpha })\n",
    "    print(error)\n",
    "    print('\\n\\n\\n*********WITH 2 HIDDEN LAYERS**********\\n\\n\\n')\n",
    "    A, error = mini_SGD(input_data, output_data, input_test_data, output_test_data, {'epochs':epochs, 'maximum_error':10e10, 'dim_layer': [2, 1, 1], 'alpha' : alpha })\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n",
      "*********WITH 1 HIDDEN LAYER***********\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "epoch_number:1\n",
      "batch_error:7.007007586480496\n",
      "\n",
      "\n",
      "epoch_number:2\n",
      "batch_error:2.4084634125573783\n",
      "\n",
      "\n",
      "epoch_number:3\n",
      "batch_error:4.812040592928824\n",
      "\n",
      "\n",
      "epoch_number:4\n",
      "batch_error:1.2036133245853051\n",
      "\n",
      "\n",
      "epoch_number:5\n",
      "batch_error:9.680900862991043\n",
      "\n",
      "\n",
      "epoch_number:6\n",
      "batch_error:5.196078926490138\n",
      "\n",
      "\n",
      "epoch_number:7\n",
      "batch_error:1.2363773087563483\n",
      "\n",
      "\n",
      "epoch_number:8\n",
      "batch_error:2.4327519943810976\n",
      "\n",
      "\n",
      "epoch_number:9\n",
      "batch_error:2.4386244517471725\n",
      "\n",
      "\n",
      "epoch_number:10\n",
      "batch_error:4.812040592928824\n",
      "\n",
      "\n",
      "epoch_number:11\n",
      "batch_error:5.196078926490138\n",
      "\n",
      "\n",
      "epoch_number:12\n",
      "batch_error:2.4852018460487004\n",
      "\n",
      "\n",
      "epoch_number:13\n",
      "batch_error:7.007007586480496\n",
      "\n",
      "\n",
      "epoch_number:14\n",
      "batch_error:2.4852018460487004\n",
      "\n",
      "\n",
      "epoch_number:15\n",
      "batch_error:3.464443878844351\n",
      "\n",
      "\n",
      "epoch_number:16\n",
      "batch_error:2.4084634125573783\n",
      "\n",
      "\n",
      "epoch_number:17\n",
      "batch_error:4.070565016205041\n",
      "\n",
      "\n",
      "epoch_number:18\n",
      "batch_error:13.147690680210893\n",
      "\n",
      "\n",
      "epoch_number:19\n",
      "batch_error:13.147690680210893\n",
      "\n",
      "\n",
      "epoch_number:20\n",
      "batch_error:2.4852018460487004\n",
      "\n",
      "\n",
      "epoch_number:21\n",
      "batch_error:4.812040592928824\n",
      "\n",
      "\n",
      "epoch_number:22\n",
      "batch_error:1.948725866559078\n",
      "\n",
      "\n",
      "epoch_number:23\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1c5301726fd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0000001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#with alpha value 0.0000001\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-91bcc8c6bcad>\u001b[0m in \u001b[0;36mf1\u001b[1;34m(alpha, epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0moutput_test_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_test_data\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*********WITH 1 HIDDEN LAYER***********\\n\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmini_SGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_test_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_test_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'maximum_error'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10e10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dim_layer'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'alpha'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'min error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n\\n*********WITH 1 HIDDEN LAYER***********'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-3287f82d8c45>\u001b[0m in \u001b[0;36mmini_SGD\u001b[1;34m(input_data, output_data, input_test_data, output_test_data, dict_)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_activations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'alpha'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m#print('{} :error: {}'.format(i+1, error))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-46ecd5c56948>\u001b[0m in \u001b[0;36mback_prop\u001b[1;34m(X, Y, W, b, activations, dim_layer, alpha)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_layer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f1(0.0000001, 10)#with alpha value 0.0000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f2(0.0000001, 10)#with alpha value 0.0000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1(0.00001, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1(0.00005, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1(0.00003, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1(0.00003, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best for f1 0.00005 for 1 and 0.00002 for next 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best for f2 is 0.00003 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858, 0.88079708, 0.95257413, 0.98201379, 0.99330715,\n",
       "       0.99752738, 0.99908895, 0.99966465, 0.99987661])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.arange(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 2 3 1 3 2 1 3 1]\n",
      "[2 3 1 3 2 1 2 1 3 1]\n",
      "[[3, 2, 2, 3, 1, 3, 2, 1, 3, 1], [2, 3, 1, 3, 2, 1, 2, 1, 3, 1]]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randint(1, 4, [10])\n",
    "b = np.random.randint(1, 4 ,[10])\n",
    "print(a)\n",
    "print(b)\n",
    "c = [list(a), list(b)]\n",
    "print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 2 9 2 3 4 1 9 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.product(c, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
